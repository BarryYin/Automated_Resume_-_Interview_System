#!/usr/bin/env python3
"""
æµ‹è¯•ç™¾åº¦æ–‡å¿ƒå¤§æ¨¡å‹é›†æˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from llm_service import llm_service
from ai_chat_service import ai_chat_service
import json

def test_llm_service():
    """æµ‹è¯•LLMæœåŠ¡"""
    print("ğŸ§ª æµ‹è¯•LLMæœåŠ¡...")
    
    # æµ‹è¯•æ•°æ®
    candidate_info = {
        "name": "å¼ ä¸‰",
        "position": "Pythonå¼€å‘å·¥ç¨‹å¸ˆ",
        "email": "zhangsan@example.com"
    }
    
    resume_text = "å…·æœ‰3å¹´Pythonå¼€å‘ç»éªŒï¼Œç†Ÿæ‚‰Djangoã€Flaskæ¡†æ¶ï¼Œæœ‰å¤§å‹é¡¹ç›®ç»éªŒã€‚"
    job_description = "æ‹›è˜Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼Œè¦æ±‚ç†Ÿæ‚‰Webå¼€å‘æ¡†æ¶ï¼Œæœ‰å›¢é˜Ÿåä½œç»éªŒã€‚"
    
    try:
        result = llm_service.generate_interview_questions(
            candidate_info, resume_text, job_description
        )
        
        print("âœ… LLMæœåŠ¡æµ‹è¯•æˆåŠŸ!")
        print(f"ğŸ“ ç”Ÿæˆäº† {len(result.get('questions', []))} ä¸ªé—®é¢˜")
        
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªé—®é¢˜
        if result.get('questions'):
            first_q = result['questions'][0]
            print(f"ğŸ” ç¤ºä¾‹é—®é¢˜: {first_q.get('question', '')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ LLMæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_ai_chat_service():
    """æµ‹è¯•AIèŠå¤©æœåŠ¡"""
    print("\nğŸ§ª æµ‹è¯•AIèŠå¤©æœåŠ¡...")
    
    try:
        result = ai_chat_service.chat_with_ai("è¯·åˆ†æä¸€ä¸‹å½“å‰çš„æ‹›è˜æ•°æ®æ¦‚å†µ")
        
        print("âœ… AIèŠå¤©æœåŠ¡æµ‹è¯•æˆåŠŸ!")
        print(f"ğŸ“ AIå›å¤é¢„è§ˆ: {result.get('response', '')[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ AIèŠå¤©æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_answer_evaluation():
    """æµ‹è¯•å›ç­”è¯„ä¼°åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•å›ç­”è¯„ä¼°åŠŸèƒ½...")
    
    try:
        question = "è¯·ä»‹ç»ä¸€ä¸‹æ‚¨çš„Pythonå¼€å‘ç»éªŒ"
        answer = "æˆ‘æœ‰3å¹´çš„Pythonå¼€å‘ç»éªŒï¼Œä¸»è¦ä½¿ç”¨Djangoæ¡†æ¶å¼€å‘Webåº”ç”¨ï¼Œå‚ä¸è¿‡ç”µå•†å¹³å°çš„åç«¯å¼€å‘ã€‚"
        dimension = "Knowledge"
        
        result = llm_service.evaluate_answer(question, answer, dimension)
        
        print("âœ… å›ç­”è¯„ä¼°æµ‹è¯•æˆåŠŸ!")
        print(f"ğŸ“Š è¯„åˆ†: {result.get('score', 0)}åˆ†")
        print(f"ğŸ’¬ åé¦ˆ: {result.get('feedback', '')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å›ç­”è¯„ä¼°æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹æµ‹è¯•ç™¾åº¦æ–‡å¿ƒå¤§æ¨¡å‹é›†æˆ...")
    print("=" * 50)
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    from config import config
    print(f"ğŸ”§ å½“å‰é…ç½®:")
    print(f"   æ¨¡å‹: {config.get('llm.model')}")
    print(f"   APIåœ°å€: {config.get('llm.base_url')}")
    print(f"   APIå¯†é’¥: {config.get('llm.api_key')[:20]}...")
    print("=" * 50)
    
    tests = [
        test_llm_service,
        test_ai_chat_service,
        test_answer_evaluation
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        if test_func():
            passed += 1
    
    print("\n" + "=" * 50)
    print(f"ğŸ‰ æµ‹è¯•å®Œæˆ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡! ç™¾åº¦æ–‡å¿ƒå¤§æ¨¡å‹é›†æˆæˆåŠŸ!")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)